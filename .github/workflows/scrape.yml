name: Hourly Rate Scraper

on:
  workflow_dispatch: # cron-job.org triggers this every hour at :00 UTC

concurrency:
  group: scrape
  cancel-in-progress: false

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 20

    strategy:
      fail-fast: false
      matrix:
        include:
          - name: Indonesia IDR
            script: run-idr.js
          - name: Thailand THB
            script: run-thb.js
          - name: Mongolia MNT
            script: run-mnt.js
          - name: Vietnam VND
            script: run-vnd.js
          - name: Nepal NPR
            script: run-npr.js
          - name: China CNY
            script: run-cny.js
          - name: Cambodia KHM
            script: run-khm.js
          - name: Myanmar MMK
            script: run-mmk.js
          - name: Philippines PHP
            script: run-php.js
          - name: Cameroon XAF
            script: run-xaf.js

    defaults:
      run:
        working-directory: scraper

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install dependencies
        run: npm install

      - name: Cache Playwright browsers
        id: playwright-cache
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: playwright-chromium-${{ hashFiles('scraper/package-lock.json') }}

      - name: Install Playwright Chromium
        if: steps.playwright-cache.outputs.cache-hit != 'true'
        run: npx playwright install chromium --with-deps

      - name: Install Playwright system dependencies
        if: steps.playwright-cache.outputs.cache-hit == 'true'
        run: npx playwright install-deps chromium

      - name: Run scraper (${{ matrix.name }})
        id: scraper
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: |
          set -o pipefail
          node ${{ matrix.script }} 2>&1 | tee scraper_output.log
          if grep -q "실패한 스크래퍼" scraper_output.log; then
            echo "has_failures=true" >> $GITHUB_OUTPUT
            {
              echo "details<<HEREDOC"
              grep -A 20 "실패한 스크래퍼" scraper_output.log
              echo "HEREDOC"
            } >> $GITHUB_OUTPUT
          else
            echo "has_failures=false" >> $GITHUB_OUTPUT
          fi

      - name: Send failure notification email
        if: steps.scraper.outputs.has_failures == 'true'
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 465
          secure: true
          username: ${{ secrets.NOTIFY_EMAIL }}
          password: ${{ secrets.GMAIL_APP_PASSWORD }}
          subject: "⚠️ [${{ matrix.name }}] 스크래퍼 부분 실패"
          to: ${{ secrets.NOTIFY_EMAIL }}
          from: ${{ secrets.NOTIFY_EMAIL }}
          body: |
            [${{ matrix.name }}] 스크래핑 중 일부 운영사가 실패했습니다.

            ${{ steps.scraper.outputs.details }}

            Actions 실행 확인:
            ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
